{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import pandas_ta as ta\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from pybit.unified_trading import HTTP\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "from binance.spot import Spot\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "pio.renderers.default = 'browser'\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching and Merging Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataManager:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.glassnode_api_key = os.getenv('GLASSNODE_API_KEY')\n",
    "        self.bybit_api_key = os.getenv('BYBIT_API_KEY')\n",
    "        self.bybit_api_secret = os.getenv('BYBIT_API_SECRET')\n",
    "        self.bybit_session = HTTP(testnet=False, api_key=self.bybit_api_key, api_secret=self.bybit_api_secret)\n",
    "        self.binance_session = Spot()\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    @staticmethod\n",
    "    def datetime_to_unix(date):\n",
    "        \"\"\"Convert a datetime object to a Unix timestamp.\"\"\"\n",
    "        return int(date.timestamp())\n",
    "\n",
    "    def _fetch_glassnode_data(self, endpoint, start, end, frequency):\n",
    "        params = {\n",
    "            'a': 'BTC',\n",
    "            's': self.datetime_to_unix(start),\n",
    "            'u': self.datetime_to_unix(end),\n",
    "            'i': frequency,\n",
    "            'f': 'JSON',\n",
    "            'api_key': self.glassnode_api_key  \n",
    "        }\n",
    "        \n",
    "        base_url = 'https://api.glassnode.com/v1/metrics'\n",
    "        url = f\"{base_url}/{endpoint}\"\n",
    "        name = re.search(r'/([^/]*)$', endpoint).group(1)\n",
    "\n",
    "        for attempt in range(3):\n",
    "            try:\n",
    "                response = requests.get(url, params=params)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    df = pd.DataFrame(data)\n",
    "                    if 't' in df.columns:\n",
    "                        df['t'] = pd.to_datetime(df['t'], unit='s')\n",
    "                    df.rename(columns={'v': name}, inplace=True)\n",
    "                    logging.info(f\"Successfully fetched data for endpoint: {endpoint}\")\n",
    "                    return df\n",
    "                else:\n",
    "                    logging.error(f\"Failed to fetch data: {response.status_code} - {response.text}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Attempt {attempt + 1}: Exception occurred while fetching data: {e}\")\n",
    "\n",
    "        raise Exception(f\"Failed to fetch data after 3 attempts for endpoint: {endpoint}\")\n",
    "    \n",
    "    def _fetch_and_merge_glassnode_data(self, endpoints, start, end, frequency):\n",
    "        data_frames = []\n",
    "\n",
    "        for endpoint in endpoints:\n",
    "            try:\n",
    "                df = self._fetch_glassnode_data(endpoint, start, end, frequency)\n",
    "                if df is not None and not df.empty:\n",
    "                    data_frames.append(df.set_index('t'))\n",
    "                else:\n",
    "                    logging.warning(f\"No data found for endpoint: {endpoint}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to fetch data for endpoint: {endpoint} with error: {e}\")\n",
    "\n",
    "        if data_frames:\n",
    "            merged_df = pd.concat(data_frames, axis=1, join='outer')\n",
    "            merged_df.reset_index(inplace=True)\n",
    "            merged_df.set_index('t', inplace=True)\n",
    "            logging.info(\"Successfully merged data from all endpoints.\")\n",
    "            return merged_df\n",
    "        else:\n",
    "            logging.warning(\"No data frames to merge.\")\n",
    "            return None\n",
    "    \n",
    "    def get_trigger_data(self, start, end, frequency='1h'):\n",
    "        short_term_endpoints = [\n",
    "            os.getenv('BTC_PRICE'),\n",
    "            os.getenv('SSR'),\n",
    "            os.getenv('SUPPLY_IN_PROFIT')\n",
    "        ]\n",
    "        return self._fetch_and_merge_glassnode_data(short_term_endpoints, start, end, frequency)\n",
    "\n",
    "    def get_context_data(self, start, end, frequency='24h'):\n",
    "        contextual_endpoints = [\n",
    "            os.getenv('BTC_PRICE'),\n",
    "            os.getenv('BTC_REALIZED_PRICE'),\n",
    "            os.getenv('PUELL_MULTIPLE'),\n",
    "            os.getenv('MVRV_Z_SCORE'),\n",
    "            os.getenv('ENTITY_ADJ_NUPL'),\n",
    "            os.getenv('ENTITY_ADJ_DORMANCY_FLOW'),\n",
    "            os.getenv('SUPPLY_IN_PROFIT')\n",
    "        ]\n",
    "        return self._fetch_and_merge_glassnode_data(contextual_endpoints, start, end, frequency)\n",
    "\n",
    "    def get_bybit_data(self, symbol='BTCUSDT', interval=60, start_time=None, end_time=None):\n",
    "        try:\n",
    "            start_time_unix = self.datetime_to_unix(start_time) * 1000 if start_time else None\n",
    "            end_time_unix = self.datetime_to_unix(end_time) * 1000 if end_time else None\n",
    "            all_data = []\n",
    "            fetched_rows = 0\n",
    "\n",
    "            while end_time_unix > start_time_unix:\n",
    "                params = {\n",
    "                    'category': 'spot',\n",
    "                    'symbol': symbol,\n",
    "                    'interval': interval,\n",
    "                    'start': start_time_unix,\n",
    "                    'end': end_time_unix,\n",
    "                    'limit': 1000\n",
    "                }\n",
    "\n",
    "                response = self.bybit_session.get_kline(**params)\n",
    "\n",
    "                if response['retCode'] == 0:\n",
    "                    data = response['result']['list']\n",
    "                    if not data:\n",
    "                        logging.info(\"No more data returned.\")\n",
    "                        break\n",
    "\n",
    "                    df = pd.DataFrame(data, columns=['start_time', 'open', 'high', 'low', 'close', 'volume', 'turnover'])\n",
    "                    df['start_time'] = pd.to_datetime(df['start_time'], unit='ms')\n",
    "                    all_data.append(df)\n",
    "                    fetched_rows += len(df)\n",
    "\n",
    "                    logging.info(f\"Fetched {len(df)} rows, total fetched: {fetched_rows}\")\n",
    "\n",
    "                    if len(df) < 1000:\n",
    "                        logging.info(\"Fetched less than 1000 rows, ending loop.\")\n",
    "                        break  # All data within the range has been retrieved\n",
    "\n",
    "                    # Update end_time_unix for the next call to avoid overlapping data\n",
    "                    earliest_timestamp = df['start_time'].iloc[-1].timestamp() * 1000\n",
    "                    end_time_unix = int(earliest_timestamp) - (interval * 60 * 1000)  # Decrement by interval in milliseconds\n",
    "                    logging.info(f\"Updated end_time_unix to {end_time_unix} for the next API call.\")\n",
    "\n",
    "                    # Wait for 5 seconds before the next API call\n",
    "                    time.sleep(1)\n",
    "\n",
    "                else:\n",
    "                    logging.error(f\"Failed to fetch ByBit data: {response['retMsg']}\")\n",
    "                    break\n",
    "\n",
    "            if all_data:\n",
    "                # Concatenate all data frames\n",
    "                final_df = pd.concat(all_data).drop_duplicates().sort_index()\n",
    "                final_df.set_index('start_time', inplace=True)\n",
    "                final_df.drop(columns='volume', inplace=True)\n",
    "                final_df = final_df.astype(float)  # Convert all columns to float\n",
    "                #logging.info(f\"Successfully fetched {fetched_rows} rows of ByBit data.\")\n",
    "                return final_df\n",
    "            else:\n",
    "                logging.warning(\"No data was fetched from ByBit.\")\n",
    "                return None\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Exception occurred while fetching ByBit data: {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_binance_data(self, symbol='BTCUSDT', interval='1h', start_time=None, end_time=None):\n",
    "            start_time_unix = self.datetime_to_unix(start_time) * 1000 if start_time else None\n",
    "            end_time_unix = self.datetime_to_unix(end_time) * 1000 if end_time else None\n",
    "            all_data = []\n",
    "            fetched_rows = 0\n",
    "\n",
    "            while start_time_unix < end_time_unix:\n",
    "                klines = self.binance_session.klines(\n",
    "                    symbol=symbol,\n",
    "                    interval=interval,\n",
    "                    startTime=start_time_unix,\n",
    "                    endTime=end_time_unix,\n",
    "                    limit=1000\n",
    "                )\n",
    "\n",
    "                if not klines:\n",
    "                    logging.info(\"No more data returned.\")\n",
    "                    break\n",
    "\n",
    "                data = []\n",
    "                for kline in klines:\n",
    "                    data.append({\n",
    "                        'start_time': pd.to_datetime(kline[0], unit='ms'),\n",
    "                        'open': float(kline[1]),\n",
    "                        'high': float(kline[2]),\n",
    "                        'low': float(kline[3]),\n",
    "                        'close': float(kline[4]),\n",
    "                        'volume': float(kline[5])\n",
    "                    })\n",
    "\n",
    "                df = pd.DataFrame(data)\n",
    "                all_data.append(df)\n",
    "                fetched_rows += len(df)\n",
    "\n",
    "                logging.info(f\"Fetched {len(df)} rows, total fetched: {fetched_rows}\")\n",
    "\n",
    "                if len(df) < 1000:\n",
    "                    logging.info(\"Fetched less than 1000 rows, ending loop.\")\n",
    "                    break  # All data within the range has been retrieved\n",
    "\n",
    "                # Update start_time_unix for the next call to avoid overlapping data\n",
    "                last_timestamp = df['start_time'].iloc[-1].timestamp() * 1000\n",
    "                start_time_unix = int(last_timestamp) + (3600 * 1000)  # Increment by 1 hour in milliseconds\n",
    "                #logging.info(f\"Updated start_time_unix to {start_time_unix} for the next API call.\")\n",
    "\n",
    "                # Wait for 5 seconds before the next API call\n",
    "                time.sleep(1)\n",
    "\n",
    "            if all_data:\n",
    "                # Concatenate all data frames\n",
    "                final_df = pd.concat(all_data).drop_duplicates().sort_index()\n",
    "                final_df.set_index('start_time', inplace=True)\n",
    "                final_df.drop(columns='volume', inplace=True)\n",
    "                final_df = final_df.astype(float)  # Convert all columns to float\n",
    "                #logging.info(f\"Successfully fetched {fetched_rows} rows of Binance data.\")\n",
    "                return final_df\n",
    "            else:\n",
    "                logging.warning(\"No data was fetched from Binance.\")\n",
    "                return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_manager = DataManager()\n",
    "\n",
    "start_date = datetime.strptime('2021-10-01', '%Y-%m-%d')\n",
    "end_date = datetime.today()\n",
    "\n",
    "binance_data = data_manager.get_binance_data(symbol='BTCUSDT', interval='1h', start_time=start_date, end_time=end_date)\n",
    "bybit_data = data_manager.get_bybit_data(symbol='BTCUSDT', start_time=start_date, end_time=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingStrategy:\n",
    "\n",
    "    def __init__(self, data_manager):\n",
    "        self.data_manager = data_manager\n",
    "\n",
    "    def compute_triggers(self, start, end):\n",
    "        start = datetime.strptime(start, '%Y-%m-%d')\n",
    "        end = datetime.strptime(end, '%Y-%m-%d')\n",
    "        \n",
    "        # Retrieve trigger data and ByBit data\n",
    "        trigger_data = self.data_manager.get_trigger_data((start - timedelta(hours=8640)), end)\n",
    "        binance_data = self.data_manager.get_binance_data(symbol='BTCUSDT', start_time=(start - timedelta(hours=8640/2)), end_time=end)\n",
    "        binance_data.rename_axis('t', inplace=True)\n",
    "        \n",
    "        \n",
    "        # Merge ByBit data with trigger data\n",
    "        if binance_data is not None:\n",
    "            trigger_data = trigger_data.merge(binance_data, left_index=True, right_index=True, how='outer')\n",
    "        \n",
    "        # Calculate indicators\n",
    "        trigger_data['rsi_ssr_smoothed'] = ta.ema(ta.rsi(trigger_data['ssr_oscillator'], length=336), length=800)\n",
    "        trigger_data['rsi_ssr_smoothed_median'] = trigger_data['rsi_ssr_smoothed'].rolling(window=240).median()\n",
    "        \n",
    "        # Clean up and filter data\n",
    "        trigger_data.drop(columns=['ssr_oscillator', 'profit_relative', 'price_usd_close'], inplace=True)\n",
    "        trigger_data = trigger_data[trigger_data.index >= start]\n",
    "        \n",
    "        return trigger_data\n",
    "\n",
    "    def compute_context(self, start, end):\n",
    "        \n",
    "        start = datetime.strptime(start, '%Y-%m-%d')\n",
    "        end = datetime.strptime(end, '%Y-%m-%d')\n",
    "        \n",
    "        # Retrieve context data\n",
    "        context_data = self.data_manager.get_context_data((start - timedelta(days=360)), end)\n",
    "\n",
    "        # Market condition calculations\n",
    "        context_data['28d_mkt_gradient'] = (context_data['price_usd_close'].diff(28) - context_data['price_realized_usd'].diff(28) - \n",
    "                                            (context_data['price_usd_close'].diff(28) - context_data['price_realized_usd'].diff(28)).expanding().mean()) / \\\n",
    "                                            (context_data['price_usd_close'].diff(28) - context_data['price_realized_usd'].diff(28)).expanding().std()\n",
    "        \n",
    "        context_data['mayer_multiple'] = context_data['price_usd_close'] / context_data['price_usd_close'].rolling(200).mean()\n",
    "        context_data['price_profit_corr'] = context_data['price_usd_close'].rolling(7).corr(context_data['profit_relative'])\n",
    "\n",
    "        # Detect market tops and bottoms\n",
    "        context_data['top_detection'] = (np.where(context_data['mvrv_z_score'] > 3.8, 1, 0) * \n",
    "                                         np.where(context_data['mayer_multiple'] >= 1.3, 1, 0) *\n",
    "                                         np.where(context_data['net_unrealized_profit_loss_account_based'] >= 0.6, 1, 0) *\n",
    "                                         np.where(context_data['28d_mkt_gradient'] >= 7, 1, 0)) * context_data['price_usd_close']\n",
    "        \n",
    "        context_data['bottom_detection'] = (np.where(context_data['mvrv_z_score'] <= 0, 1, 0) * \n",
    "                                            np.where(context_data['mayer_multiple'] <= 0.8, 1, 0) *\n",
    "                                            np.where(context_data['price_usd_close'] <= context_data['price_realized_usd'], 1, 0) *\n",
    "                                            np.where(context_data['net_unrealized_profit_loss_account_based'] <= 0, 1, 0) *\n",
    "                                            np.where(context_data['puell_multiple'] <= 0.5, 1, 0) *\n",
    "                                            np.where(context_data['dormancy_flow'] <= 200000, 1, 0)) * context_data['price_usd_close']\n",
    "\n",
    "        # Apply context determination\n",
    "        context_data['context'] = context_data.apply(self.determine_context, axis=1)\n",
    "        context_data['context'].fillna(method='ffill', inplace=True)\n",
    "        context_data.drop(columns=['top_detection', 'bottom_detection'], inplace=True)\n",
    "        context_data = context_data[context_data.index >= start]\n",
    "        \n",
    "        return context_data\n",
    "\n",
    "    @staticmethod\n",
    "    def determine_context(row):\n",
    "        if row['bottom_detection'] != 0 and (row['top_detection'] == 0 or row.name < row.index[row['top_detection'] != 0].max()):\n",
    "            return int(1)\n",
    "        elif row['top_detection'] != 0 and (row['bottom_detection'] == 0 or row.name < row.index[row['bottom_detection'] != 0].max()):\n",
    "            return int(0)\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "    def merge_data(self, trigger_data, context_data):\n",
    "        # Ensure proper alignment of the data indices before merging\n",
    "        trigger_data.reset_index(inplace=True)\n",
    "        context_data.reset_index(inplace=True)\n",
    "        context_data['t'] = context_data['t'].dt.tz_localize(None)  # Ensure no timezone differences\n",
    "        \n",
    "        # Merge the datasets\n",
    "        full_data = pd.merge_asof(trigger_data, context_data[['t', 'context']], on='t', direction='forward')\n",
    "        full_data['context'] = full_data['context'].ffill()\n",
    "        full_data.set_index('t', inplace=True)\n",
    "\n",
    "        return full_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingEnvironment:\n",
    "    def __init__(self, data, window_size, scaler=StandardScaler()):\n",
    "        self.data = data\n",
    "        self.window_size = window_size\n",
    "        self.cash = 10000\n",
    "        self.initial_cash = 10000  # Starting cash\n",
    "        self.bitcoin = 0  # Bitcoin holding, positive for long, negative for short\n",
    "        self.entry_price = 0  # Price at which the last trade was executed\n",
    "        self.net_worth = self.cash  # Net worth initialized to starting cash\n",
    "        self.scaler = scaler  # Optional scaler\n",
    "        self.scaled_data = pd.DataFrame(scaler.fit_transform(self.data), columns=self.data.columns, index=self.data.index)\n",
    "        self.current_step = 0\n",
    "        self.position_state = 0  # 0: long, 1: cash, 2: short\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = self.window_size\n",
    "        self.cash = 10000\n",
    "        self.bitcoin = 0\n",
    "        self.entry_price = 0\n",
    "        self.net_worth = self.cash\n",
    "        self.position_state = 0\n",
    "        return self._get_state()\n",
    "\n",
    "    def _get_state(self):\n",
    "        state_columns = [col for col in self.scaled_data.columns if col != 'context']\n",
    "        state = self.scaled_data[state_columns].iloc[self.current_step - self.window_size:self.current_step].values\n",
    "        return state.astype(float)\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.current_step + 1 >= len(self.data):\n",
    "            raise IndexError(\"Attempted to step beyond the data boundary.\")\n",
    "\n",
    "        current_price = self.data.iloc[self.current_step]['price_usd_close']\n",
    "        \n",
    "        if action == 1:  # Long\n",
    "            if self.position_state != 1 and self.cash > 0:\n",
    "                self.bitcoin = self.cash / current_price\n",
    "                self.entry_price = current_price\n",
    "                self.cash = 0\n",
    "                self.position_state = 1\n",
    "\n",
    "        elif action == 0:  # Cash\n",
    "            if self.position_state == 1:  # Closing long\n",
    "                self.cash = self.bitcoin * current_price\n",
    "                self.bitcoin = 0\n",
    "            elif self.position_state == -1:  # Closing short\n",
    "                profit = -self.bitcoin * (self.entry_price - current_price)\n",
    "                self.cash += profit\n",
    "                self.bitcoin = 0\n",
    "            self.position_state = 0\n",
    "\n",
    "        elif action == -1:  # Short\n",
    "            if self.position_state != -1 and self.cash > 0:\n",
    "                self.bitcoin = -self.cash / current_price  # Short position\n",
    "                self.entry_price = current_price\n",
    "                self.cash = 0\n",
    "                self.position_state = -1\n",
    "\n",
    "        \n",
    "        self.net_worth = self.cash + (self.bitcoin * current_price if self.bitcoin > 0 else 0)\n",
    "        \n",
    "        # Calculate reward based on net worth change, not just final amount\n",
    "        reward = self.net_worth - self.initial_cash\n",
    "        \n",
    "        if reward > 0:\n",
    "            reward = 1\n",
    "        elif reward < 0:\n",
    "            reward = -1\n",
    "        else:\n",
    "            reward = 0\n",
    "        self.current_step += 1\n",
    "        done = self.net_worth <= 0 or self.current_step >= len(self.data) - 1\n",
    "\n",
    "        return self._get_state(), reward, done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuelingQNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(DuelingQNetwork, self).__init__()\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.fc1 = nn.Linear(state_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        \n",
    "        # Value stream\n",
    "        self.value_fc = nn.Linear(256, 1)\n",
    "        \n",
    "        # Advantage stream\n",
    "        self.advantage_fc = nn.Linear(256, action_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        \n",
    "        value = self.value_fc(x)\n",
    "        advantage = self.advantage_fc(x)\n",
    "        \n",
    "        q_value = value + (advantage - advantage.mean(dim=1, keepdim=True))\n",
    "        return q_value.squeeze(1)\n",
    "\n",
    "class DuelingDQNAgent:\n",
    "    def __init__(self, state_size, action_size):    \n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.99\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "        self.target_model = self._build_model()\n",
    "        self.update_target_model()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def _build_model(self):\n",
    "        return DuelingQNetwork(self.state_size, self.action_size)\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state, context):\n",
    "        # Exploration: Random actions based on context\n",
    "        if random.random() <= self.epsilon:\n",
    "            if context == 1:\n",
    "                return random.choice([0, 1])  # Long or Cash\n",
    "            elif context == 0:\n",
    "                return random.choice([-1, 0])  # Cash or Short\n",
    "\n",
    "        # Prepare the state for the model\n",
    "        state = torch.FloatTensor(state).reshape(-1, self.state_size).unsqueeze(0)\n",
    "\n",
    "        # Exploitation: Choose the best action based on the Q-values from the model\n",
    "        act_values = self.model(state)  # Retrieve Q-values from the model\n",
    "        print(act_values)\n",
    "        if context == 1:\n",
    "            # Only consider Long or Cash\n",
    "            return torch.argmax(act_values[:, :2], 1).item()  # Index 0 for Cash, 1 for Long\n",
    "        elif context == 0:\n",
    "            # Only consider Cash or Short\n",
    "            action = torch.argmax(act_values[:, 1:], 1).item()  # This will be 0 for Long, 1 for Short\n",
    "            \n",
    "            if action == 0:\n",
    "                return 0  # Cash\n",
    "            else:\n",
    "                return -1  # Short\n",
    "\n",
    "        # If no context restriction, choose the best overall action\n",
    "        return torch.argmax(act_values, 1).item()  # Choose the action with the highest Q-value\n",
    "\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            \n",
    "            state = torch.FloatTensor(state).reshape(-1, self.state_size)\n",
    "            next_state = torch.FloatTensor(next_state).reshape(-1, self.state_size)\n",
    "            \n",
    "            current_qs = self.model(state)\n",
    "            next_qs_target = self.target_model(next_state)\n",
    "            \n",
    "            max_next_qs = torch.max(next_qs_target, dim=1)[0]\n",
    "            target_qs = current_qs.clone().detach()\n",
    "            targets = reward + self.gamma * max_next_qs * (1 - done)  # Done flag to zero out terminal states\n",
    "            \n",
    "            target_qs[0, action] = targets\n",
    "            \n",
    "            loss = nn.MSELoss()(current_qs, target_qs)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        # Epsilon decay\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_state_dict(torch.load(name))\n",
    "\n",
    "    def save(self, name):\n",
    "        torch.save(self.model.state_dict(), name)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn(agent, env, repetitions, batch_size):\n",
    "    for rep in range(repetitions):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        steps = 0\n",
    "        while True:\n",
    "            context = env.data.iloc[env.current_step]['context']\n",
    "            action = agent.act(state, context)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "\n",
    "            print(f\"Rep: {rep}, Step: {steps}, Action: {action}, Reward: {reward}, Done: {done}\")\n",
    "\n",
    "            if done:\n",
    "                print(f\"Training completed for Repetition {rep+1}. Total Steps: {steps}, Total Reward: {total_reward}\")\n",
    "                break\n",
    "\n",
    "            if len(agent.memory) > batch_size:\n",
    "                agent.replay(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>rsi_ssr_smoothed</th>\n",
       "      <th>rsi_ssr_smoothed_median</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-30 00:00:00</td>\n",
       "      <td>6597.66</td>\n",
       "      <td>6597.66</td>\n",
       "      <td>6557.70</td>\n",
       "      <td>6577.30</td>\n",
       "      <td>47.884933</td>\n",
       "      <td>47.435209</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-30 01:00:00</td>\n",
       "      <td>6577.31</td>\n",
       "      <td>6607.43</td>\n",
       "      <td>6570.20</td>\n",
       "      <td>6595.48</td>\n",
       "      <td>47.890065</td>\n",
       "      <td>47.435631</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-30 02:00:00</td>\n",
       "      <td>6595.47</td>\n",
       "      <td>6602.00</td>\n",
       "      <td>6570.00</td>\n",
       "      <td>6575.16</td>\n",
       "      <td>47.894873</td>\n",
       "      <td>47.436323</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-30 03:00:00</td>\n",
       "      <td>6574.54</td>\n",
       "      <td>6584.24</td>\n",
       "      <td>6570.00</td>\n",
       "      <td>6580.00</td>\n",
       "      <td>47.899770</td>\n",
       "      <td>47.437415</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-30 04:00:00</td>\n",
       "      <td>6576.34</td>\n",
       "      <td>6581.99</td>\n",
       "      <td>6552.44</td>\n",
       "      <td>6552.49</td>\n",
       "      <td>47.904119</td>\n",
       "      <td>47.438184</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50399</th>\n",
       "      <td>2024-06-29 23:00:00</td>\n",
       "      <td>60970.00</td>\n",
       "      <td>61059.37</td>\n",
       "      <td>60940.00</td>\n",
       "      <td>60986.68</td>\n",
       "      <td>47.508964</td>\n",
       "      <td>48.264516</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50400</th>\n",
       "      <td>2024-06-30 00:00:00</td>\n",
       "      <td>60986.68</td>\n",
       "      <td>61078.01</td>\n",
       "      <td>60922.00</td>\n",
       "      <td>61024.55</td>\n",
       "      <td>47.504625</td>\n",
       "      <td>48.253343</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50401</th>\n",
       "      <td>2024-06-30 01:00:00</td>\n",
       "      <td>61024.55</td>\n",
       "      <td>61043.44</td>\n",
       "      <td>60930.03</td>\n",
       "      <td>60961.99</td>\n",
       "      <td>47.500037</td>\n",
       "      <td>48.242261</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50402</th>\n",
       "      <td>2024-06-30 02:00:00</td>\n",
       "      <td>60961.99</td>\n",
       "      <td>60961.99</td>\n",
       "      <td>60740.94</td>\n",
       "      <td>60834.27</td>\n",
       "      <td>47.495165</td>\n",
       "      <td>48.232336</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50403</th>\n",
       "      <td>2024-06-30 03:00:00</td>\n",
       "      <td>60834.27</td>\n",
       "      <td>60949.36</td>\n",
       "      <td>60791.98</td>\n",
       "      <td>60898.32</td>\n",
       "      <td>47.490305</td>\n",
       "      <td>48.223380</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50404 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         t      open      high       low     close  \\\n",
       "0      2018-09-30 00:00:00   6597.66   6597.66   6557.70   6577.30   \n",
       "1      2018-09-30 01:00:00   6577.31   6607.43   6570.20   6595.48   \n",
       "2      2018-09-30 02:00:00   6595.47   6602.00   6570.00   6575.16   \n",
       "3      2018-09-30 03:00:00   6574.54   6584.24   6570.00   6580.00   \n",
       "4      2018-09-30 04:00:00   6576.34   6581.99   6552.44   6552.49   \n",
       "...                    ...       ...       ...       ...       ...   \n",
       "50399  2024-06-29 23:00:00  60970.00  61059.37  60940.00  60986.68   \n",
       "50400  2024-06-30 00:00:00  60986.68  61078.01  60922.00  61024.55   \n",
       "50401  2024-06-30 01:00:00  61024.55  61043.44  60930.03  60961.99   \n",
       "50402  2024-06-30 02:00:00  60961.99  60961.99  60740.94  60834.27   \n",
       "50403  2024-06-30 03:00:00  60834.27  60949.36  60791.98  60898.32   \n",
       "\n",
       "       rsi_ssr_smoothed  rsi_ssr_smoothed_median  context  \n",
       "0             47.884933                47.435209      0.0  \n",
       "1             47.890065                47.435631      0.0  \n",
       "2             47.894873                47.436323      0.0  \n",
       "3             47.899770                47.437415      0.0  \n",
       "4             47.904119                47.438184      0.0  \n",
       "...                 ...                      ...      ...  \n",
       "50399         47.508964                48.264516      1.0  \n",
       "50400         47.504625                48.253343      1.0  \n",
       "50401         47.500037                48.242261      1.0  \n",
       "50402         47.495165                48.232336      1.0  \n",
       "50403         47.490305                48.223380      1.0  \n",
       "\n",
       "[50404 rows x 8 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.read_csv('/Users/valter.rebelo/alfa_trader/ALFA_TRADER/data/full_data_binance.csv')\n",
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_manager = DataManager()\n",
    "strategy = TradingStrategy(data_manager)\n",
    "\n",
    "#start = '2018-09-30' # data onde temos o primeiro indicador point do SRS \n",
    "#end = '2024-06-30'\n",
    "\n",
    "#context_data = strategy.compute_context('2011-08-10', end) # é preciso de mais data points para calcular o contexto de mercado\n",
    "#trigger_data = strategy.compute_triggers(start, end)\n",
    "#full_data = strategy.merge_data(trigger_data, context_data)\n",
    "\n",
    "full_data = pd.read_csv('/Users/valter.rebelo/alfa_trader/ALFA_TRADER/data/full_data_binance.csv')\n",
    "env = TradingEnvironment(full_data, window_size=10) # must be mindful of window size (days)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "state_size = env._get_state().shape[0] * env._get_state().shape[1]\n",
    "print(state_size)\n",
    "action_size = 3  # Long, Cash, Short\n",
    "agent = DuelingDQNAgent(state_size, action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep: 0, Step: 1, Action: -1, Reward: -1, Done: True\n",
      "Training completed for Repetition 1. Total Steps: 1, Total Reward: -1\n",
      "Rep: 1, Step: 1, Action: -1, Reward: -1, Done: True\n",
      "Training completed for Repetition 2. Total Steps: 1, Total Reward: -1\n",
      "Rep: 2, Step: 1, Action: 0, Reward: 0, Done: False\n",
      "Rep: 2, Step: 2, Action: -1, Reward: -1, Done: True\n",
      "Training completed for Repetition 3. Total Steps: 2, Total Reward: -1\n"
     ]
    }
   ],
   "source": [
    "train_dqn(agent=agent, env=env, repetitions=3, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backtester:\n",
    "    \n",
    "    def __init__(self, environment, agent, initial_capital=10000):\n",
    "        self.data = environment\n",
    "        self.agent = agent\n",
    "        self.window_size = environment.window_size\n",
    "        self.initial_capital = initial_capital\n",
    "        self.results = {}\n",
    "        self.run_backtest()\n",
    "\n",
    "    def run_backtest(self):\n",
    "        self.data.data['position'] = 0\n",
    "        self.cash = self.initial_capital\n",
    "        self.bitcoin = 0\n",
    "        self.net_worth = self.cash\n",
    "        self.positions = []\n",
    "\n",
    "        for i in range(self.window_size, len(self.data)):\n",
    "            state = self.data.iloc[i-self.window_size:i].values\n",
    "            context = self.data.iloc[i]['context']\n",
    "            action = self.agent.act(state, context)\n",
    "\n",
    "            current_price = self.data.iloc[i]['price_usd_close']\n",
    "\n",
    "            if context == 1:\n",
    "                if action == 0 and self.cash > 0:  # Long\n",
    "                    self.bitcoin += self.cash / current_price\n",
    "                    self.cash = 0\n",
    "                    self.positions.append((self.data.index[i], 'long'))\n",
    "                elif action == 1:  # Cash\n",
    "                    pass\n",
    "            elif context == 0:\n",
    "                if action == 1 and self.cash > 0:  # Cash\n",
    "                    pass\n",
    "                elif action == 2 and self.bitcoin > 0:  # Short\n",
    "                    self.cash += self.bitcoin * current_price\n",
    "                    self.bitcoin = 0\n",
    "                    self.positions.append((self.data.index[i], 'short'))\n",
    "\n",
    "            self.net_worth = self.cash + self.bitcoin * current_price\n",
    "            self.data.loc[self.data.index[i], 'net_worth'] = self.net_worth\n",
    "\n",
    "        self.calculate_statistics()\n",
    "\n",
    "    def calculate_statistics(self):\n",
    "        self.results['Start'] = self.data.index.min()\n",
    "        self.results['End'] = self.data.index.max()\n",
    "        self.results['Duração'] = self.results['End'] - self.results['Start']\n",
    "        self.results['Tempo de Exposição [%]'] = np.mean(self.data['position'] != 0) * 100\n",
    "        self.results['Saldo Final [$]'] = self.data['net_worth'].iloc[-1]\n",
    "        self.results['Pico de Valor [$]'] = self.data['net_worth'].max()\n",
    "        self.results['Retorno AlfaTrader [%]'] = ((self.results['Saldo Final [$]'] / self.initial_capital - 1) * 100)\n",
    "        self.results['Retorno Buy & Hold [%]'] = ((self.data['price_usd_close'].iloc[-1] / self.data['price_usd_close'].iloc[0] - 1) * 100)\n",
    "        self.results['Retorno (Ann.) [%]'] = self.results['Retorno AlfaTrader [%]'] / (self.results['Duração'].days / 365.25)\n",
    "        self.results['Volatilidade (Ann.) [%]'] = self.data['strategy_return'].std() * np.sqrt(365*24) * 100\n",
    "\n",
    "        # Filter to include only non-zero returns or when the strategy is active\n",
    "        active_returns = self.data['strategy_return'][self.data['strategy_return'] != 0]\n",
    "\n",
    "        # Calculate Sharpe Ratio using non-zero returns\n",
    "        if active_returns.empty:\n",
    "            self.results['Sharpe Ratio'] = 0  # Handle case where there are no active returns\n",
    "        else:\n",
    "            self.results['Sharpe Ratio'] = (active_returns.mean() / self.data['strategy_return'].std()) * np.sqrt(8760)\n",
    "\n",
    "        # Calculate negative returns for the downside deviation\n",
    "        negative_returns = self.data['strategy_return'][self.data['strategy_return'] < 0]\n",
    "\n",
    "        # Calculate Sortino Ratio using non-zero returns and downside deviation\n",
    "        if not negative_returns.empty and not active_returns.empty:\n",
    "            mean_active_returns = active_returns.mean()\n",
    "            downside_deviation = negative_returns.std()\n",
    "            annual_factor = np.sqrt(8760)  # Assuming 24/7 trading for crypto markets\n",
    "            self.results['Sortino Ratio'] = (mean_active_returns / downside_deviation) * annual_factor\n",
    "        else:\n",
    "            self.results['Sortino Ratio'] = 0  # Handle case where there are no negative returns or active returns\n",
    "\n",
    "        # Trading statistics\n",
    "        trades = self.data['position'].diff().fillna(0) != 0\n",
    "        self.results['# Trades'] = trades.sum()\n",
    "\n",
    "    def get_results(self):\n",
    "        return pd.DataFrame([self.results])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyVisualizer:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def plot_results(self):\n",
    "        # Create subplots: one for portfolio values and one for BTC price with signals\n",
    "        fig = make_subplots(rows=2, cols=1, shared_xaxes=True, \n",
    "                            vertical_spacing=0.1, subplot_titles=('Valor do Portfólio', 'Preço BTC com Sinais'))\n",
    "\n",
    "        # Plotting portfolio values: Strategy vs Buy & Hold\n",
    "        fig.add_trace(go.Scatter(x=self.data.index, y=self.data['strategy_cumulative_return'], name='AlfaTrader ®', line=dict(color='green')), row=1, col=1)\n",
    "        #fig.add_trace(go.Scatter(x=self.data.index, y=self.data['price_usd_close'], name='BTC', line=dict(color='blue')), row=1, col=1)\n",
    "        fig.add_trace(go.Scatter(x=self.data.index, y=self.data['market_portfolio_cumulative_return'], name='Comprar e Segurar', line=dict(color='blue')), row=1, col=1)\n",
    "        # BTC Price and action markers\n",
    "        fig.add_trace(go.Scatter(x=self.data.index, y=self.data['price_usd_close'], name='Preço BTC', line=dict(color='black')), row=2, col=1)\n",
    "\n",
    "        # Adding markers only at points of action change\n",
    "        action_changes = self.data[self.data['action'] != self.data['action'].shift(1)]\n",
    "        buys = action_changes[action_changes['action'] == 'long']\n",
    "        cash = action_changes[action_changes['action'] == 'cash']\n",
    "        shorts = action_changes[action_changes['action'] == 'short']\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=buys.index, y=buys['price_usd_close'], mode='markers', marker=dict(color='#4AD811', size=8, symbol='triangle-up'), name='Compra'), row=2, col=1)\n",
    "        fig.add_trace(go.Scatter(x=cash.index, y=cash['price_usd_close'], mode='markers', marker=dict(color='#FFCC2D', size=8, symbol='square'), name='Caixa'), row=2, col=1)\n",
    "        fig.add_trace(go.Scatter(x=shorts.index, y=shorts['price_usd_close'], mode='markers', marker=dict(color='#C70039', size=8, symbol='triangle-down'), name='Venda'), row=2, col=1)\n",
    "\n",
    "        # Update layout\n",
    "        fig.update_layout(height=800, width=1000, title_text=\"\", hovermode=\"x unified\", plot_bgcolor='white', paper_bgcolor='white', font=dict(color='black'))\n",
    "        fig.show()\n",
    "\n",
    "\n",
    "\n",
    "    def plot_btc_with_signals(self):\n",
    "        # Create a figure with custom subplots\n",
    "        fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "        # Plotting BTC price as a line graph\n",
    "        fig.add_trace(go.Scatter(x=self.data.index, y=self.data['price_usd_close'], name='Preço BTC', line=dict(color='blue')), secondary_y=False)\n",
    "\n",
    "        # Ensure that only points where detection is marked as '1' have non-zero heights\n",
    "        # Top detections as green bars\n",
    "        top_heights = self.data['price_usd_close'].where(self.data['top_detection'] != 0, 0)\n",
    "        fig.add_trace(go.Bar(x=self.data.index, y=top_heights, name='Detecção de Topo', marker_color='green'), secondary_y=False)\n",
    "\n",
    "        # Bottom detections as red bars\n",
    "        bottom_heights = self.data['price_usd_close'].where(self.data['bottom_detection'] != 0, 0)\n",
    "        fig.add_trace(go.Bar(x=self.data.index, y=bottom_heights, name='Detecção de Fundo', marker_color='red'), secondary_y=False)\n",
    "\n",
    "        # Update layout for aesthetics and readability\n",
    "        fig.update_layout(\n",
    "            title='Preço BTC com Indicadores de Topo e Fundo',\n",
    "            xaxis_title='',\n",
    "            yaxis_title='Preço BTC',\n",
    "            legend_title='Legenda',\n",
    "            hovermode='x unified',\n",
    "            plot_bgcolor='white',\n",
    "            paper_bgcolor='white',\n",
    "            font=dict(color='black')\n",
    "        )\n",
    "\n",
    "        # Adjust the y-axes visual appearance\n",
    "        fig.update_yaxes(title_text=\"Preço BTC\", secondary_y=False)\n",
    "\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = StrategyVisualizer(final_data)\n",
    "#visualizer.plot_btc_with_signals()\n",
    "visualizer.plot_results()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
